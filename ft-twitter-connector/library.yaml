# Copyright (c) 2023 Intel Corporation
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of
# this software and associated documentation files (the "Software"), to deal in
# the Software without restriction, including without limitation the rights to
# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
# the Software, and to permit persons to whom the Software is furnished to do so,
# subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
#
# SPDX-License-Identifier: MIT

---
title: Twitter Connector # required on creation, a slug will be generated from the title? -> inference-library
version: 1.0.14 # required
description: "sample description" # optional
icon: python # optional

# Optional properties for crediting authors
author: "cnvrg"
author_email: "libhub@cnvrg.io"

# At least one tag [inference, training, data] must be present
tags:
  - training

# Available only for training (exec tasks) libraries only
command: python3 pull_twitter_data.py

# These will replace the "compute" argument, values must be >= 0:
# We need to add requirement for distributed pods
requirements:
  cpu: 1.5
  memory: 2
  gpu: 0
  hpu: 0

# This will replace the "docker_images" argument (?) need to work in cnvrg as well
image: python:3.8

# This will replace "env_setup", currently only python 3 is supported.
language: python3

arguments:
  # Training arguments will have type and value, valid types are [discrete, float, integer, categorical]
  # Empty value will mark the argument as 'required', adding a default value will place it in the flow.
  - key: token
    type: 'categorical'
    values:
    - ''
  - key: term
    type: 'categorical'
    values:
      - 'World Cup'
  - key: dataset
    type: 'categorical'
    values:
      - ''
  - key: output_file
    type: 'categorical'
    values:
      - 'twitts_worldcup.csv'
  - key: max_twitts
    type: 'discrete'
    values:
      - '100'
  - key: end_point
    type: 'categorical'
    values:
      - 'recent'
  - key: days_back
    type: 'discrete'
    values:
      - '3'