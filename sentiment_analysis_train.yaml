---
title: FT Sentiment Train # Required on creation, replaces the "flow" parameter
version: 1.0.0 # Required
description: Analyze sentiment analysis in text
long_description: This blueprint allows you to fine tune a pre-trained bert model and deploy that can analyse sentiment in text absed on your data
# Optional properties for crediting authors
author: "cnvrg"
author_email: "info@cnvrg.io"

# At least one tag [inference, training, data] must be present
tags:
  - training
  - nlp

# List of tasks (libraries)
tasks:
  - title: Fine Tune S3 Connector
    top: 300
    left: 0

    # Type must be according to the flow task conventions (data, exec, deploy)
    type: exec

    # The library data
    library: fine-tune-s3-connector
    library_version: 1.0.7

    # The flattened library parameters (in this case we have training library)
    command: python3 ft-s3-connector.py

    requirements:
      cpu: 3.5
      memory: 8
      gpu: 0
      hpu: 0

    image: cnvrg:v5.0
    language: python3

    # The "arguments" property changes to "params", rest remains the same.
    # Params in the blueprint yaml can be used to override the arguments in the library.
    params:
      - key: endpoint
        type: 'categorical'
        values:
          - 'http://s3.amazonaws.com download'
      - key: bucketname
        type: 'categorical'
        values:
          - 'libhub-readme'
      - key: localdir
        type: 'categorical'
        values:
          - '/cnvrg'
      - key: prefix
        type: 'categorical'
        values:
          - 'sentiment_analysis_data/'
  - title: Fine Tune Dataset Split
    top: 300
    left: 200

    # Type must be according to the flow task conventions (data, exec, deploy)
    type: exec

    # The library data
    library: fine-tune-dataset-split
    library_version: 1.0.7

    # The flattened library parameters (in this case we have training library)
    command: python3 dataset_split.py

    requirements:
      cpu: 3.5
      memory: 8
      gpu: 0
      hpu: 0

    image: python:3.8
    language: python3

    # The "arguments" property changes to "params", rest remains the same.
    # Params in the blueprint yaml can be used to override the arguments in the library.
    params:
      - key: dataset_path
        type: categorical
        values:
          - /input/fine_tune_s3_connector/sentiment_analysis_data/1.6m_twitts.csv
      - key: valid_size
        type: categorical
        values:
          - '0.01'
  - title: Fine Tune Sentiment
    top: 300
    left: 400

    # Type must be according to the flow task conventions (data, exec, deploy)
    type: exec

    # The library data
    library: fine-tune-sentiment
    library_version: 1.0.7

    # The flattened library parameters (in this case we have training library)
    command: python3 fine-tune.py

    requirements:
      cpu: 3.5
      memory: 8
      gpu: 0
      hpu: 0

    image: python:3.8
    language: python3

    # The "arguments" property changes to "params", rest remains the same.
    # Params in the blueprint yaml can be used to override the arguments in the library.
    params:
      - key: input_filename
        type: 'categorical'
        values:
          - '/input/fine_tune_dataset_split/1.6m_twitts_small_small.csv'
      - key: output_model_path
        type: 'categorical'
        values:
          - '/cnvrg/output'
      - key: text_column
        type: 'categorical'
        values:
          - 'text'
      - key: label_column
        type: 'categorical'
        values:
          - 'target'
      - key: num_train_epochs
        type: 'discrete'
        values:
          - '1'
      - key: max_length
        type: 'discrete'
        values:
          - '300'
      - key: batch_size_train
        type: 'discrete'
        values:
          - '256'
      - key: batch_size_val
        type: 'discrete'
        values:
          - '256'
  - title: Fine Tune Inference Tw
    top: 400
    left: 500

    # Type must be according to the flow task conventions (data, exec, deploy)
    type: exec

    # The library data
    library: fine-tune-inference-tw
    library_version: 1.0.7

    # The flattened library parameters (in this case we have inference library)
    command: python3 fine-tune-inference.py

    requirements:
      cpu: 3.5
      memory: 8
      gpu: 0
      hpu: 0

    image: python:3.8
    language: python3
    accept_files: false

    # The "arguments" property changes to "params", rest remains the same.
    # Params in the blueprint yaml can be used to override the arguments in the library.
    params:
      - key: input_filename
        type: 'categorical'
        values:
        - '/input/fine_tune_dataset_split/1.6m_twitts_small_small_inference.csv'
      - key: model_path
        type: 'categorical'
        values:
        - '/input/fine_tune_sentiment/output/checkpoint-1'
      - key: result_path
        type: 'categorical'
        values:
          - '/cnvrg'
      - key: text_column
        type: 'categorical'
        values:
          - 'text'

relations:
  - from: Fine Tune S3 Connector
    to: Fine Tune Dataset Split
  - from: Fine Tune Dataset Split
    to: Fine Tune Sentiment
  - from: Fine Tune Sentiment
    to: Fine Tune Inference Tw